{"docstore/data":{"79879388-501a-4ea0-816d-a4f47286c01c":{"indexId":"79879388-501a-4ea0-816d-a4f47286c01c","nodesDict":{"f4dad3f2-be85-4ee9-a473-860ca2b3a80e":{"id_":"f4dad3f2-be85-4ee9-a473-860ca2b3a80e","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"NEXT":{"nodeId":"e5fb3ac8-42f1-4f42-a44e-e971bb964a76","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"tMdcTal8Wo9HQimeGzGrhoIp3Zp9DyNWWf6t3Fcw+/c="}},"hash":"/35XTNE79o/GJT/MO7qtoHKUzcsvkM+c9I9ijq4e3Hg=","text":"# Retail Mail: Physical Standards for Letters, Cards, Flats, and Parcels\n\n101\n101.1.2\n\n# 101 Physical Standards\n\n# Overview\n\n1.0 Physical Standards for Letters\n\n2.0 Physical Standards for Flats\n\n3.0 Physical Standards for Parcels\n\n4.0 Additional Physical Standards for Priority Mail Express\n\n5.0 Additional Physical Standards for Priority Mail\n\n6.0 Additional Physical Standards for First-Class Mail and USPS Ground Advantage — Retail\n\n7.0 Additional Physical Standards for Media Mail and Library Mail\n\n# 1.0 Physical Standards for Letters\n\n# 1.1 Dimensional Standards for Letters\n\nLetter-size mail is the following:\n\n- a. Not less than 5 inches long, 3-1/2 inches high, and 0.007-inch thick. For pieces more than 6 inches long or 4-1/4 inches high, the minimum thickness is 0.009. (Pieces not meeting the 0.009 thickness are subject to a nonmachinable surcharge under 1.2f. )\n- b. Not more than 11-1/2 inches long, or more than 6-1/8 inches high, or more than 1/4-inch thick. - c. Not more than 3.5 ounces. (Charge flat-size prices for First-Class Mail letter-size pieces over 3.5 ounces. )\n- d. Rectangular, with four square corners and parallel opposite sides. Letter-size, card-type mailpieces made of cardstock may have finished corners that do not exceed a radius of 0.125 inch (1/8 inch). See Exhibit 201.1.1.1. # 1.2 Nonmachinable Criteria\n\nA letter-size piece is nonmachinable if it has one or more of the following characteristics (see 601.1.1.2 to determine the length, height, top, and bottom of a mailpiece):\n\n- a. Has an aspect ratio (length divided by height) of less than 1.3 or more than 2.5. - b. Is polybagged, polywrapped, enclosed in any plastic material, or has an exterior surface made of a material that is not paper. Windows in envelopes made of paper do not make mailpieces nonmachinable.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"e5fb3ac8-42f1-4f42-a44e-e971bb964a76":{"id_":"e5fb3ac8-42f1-4f42-a44e-e971bb964a76","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"PREVIOUS":{"nodeId":"f4dad3f2-be85-4ee9-a473-860ca2b3a80e","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"/35XTNE79o/GJT/MO7qtoHKUzcsvkM+c9I9ijq4e3Hg="},"NEXT":{"nodeId":"f4ce8987-74c6-411d-affc-04f9fd763ce6","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"zjGjN57IYt9Ofo+ryCEhLjE5JT91yYYqrPJD8jIHRIY="}},"hash":"tMdcTal8Wo9HQimeGzGrhoIp3Zp9DyNWWf6t3Fcw+/c=","text":"Windows in envelopes made of paper do not make mailpieces nonmachinable. Attachments allowable under applicable eligibility standards do not make mailpieces nonmachinable. - c. Has clasps, strings, buttons, or similar closure devices. Domestic Mail Manual • Updated 7-9-23\n---\n# Retail Mail: Physical Standards for Letters, Cards, Flats, and Parcels\n\n101\n\n101.2.1\n\nd. Contains items such as pens, pencils, keys, or coins that cause the thickness of the mailpiece to be uneven; or loose keys or coins or similar objects not affixed to the contents within the mailpiece. Loose items may cause a letter to be nonmailable when mailed in paper envelopes (see 601.3.3). e. Is too rigid (does not bend easily when subjected to a transport belt tension of 40 pounds around an 11-inch diameter turn). f. Is less than 0.009 inches thick if the mailpiece is more than 6 inches long or 4-1/4 inches high. g. Has a delivery address parallel to the shorter dimension of the mailpiece. h. Is a self-mailer that is not prepared according to 201.3.14. i. Is a booklet that is not prepared according to 201.3.16. # Physical Standards for Flats\n\n# General Definition of Flat-Size Mail\n\nFlat-size mail is the following:\n\na. More than 11-1/2 inches long, or more than 6-1/8 inches high, or more than 1/4 inch thick, except as allowed for EDDM-Retail flats under 140. For general retail mailability, all pieces 1/4 inch thick or less must be a minimum of 5 inches long and 3-1/2 inches high and 0.007 inch thick. b. Not more than 15 inches long, or more than 12 inches high, or more than 3/4 inch thick. c. Flexible (see 2.3). d. Rectangular with four square corners or with finished corners that do not exceed a radius of 0.125 inch (1/8 inch). See Exhibit 201.1.1.1. e. Uniformly thick (see 2.4). f.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"f4ce8987-74c6-411d-affc-04f9fd763ce6":{"id_":"f4ce8987-74c6-411d-affc-04f9fd763ce6","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"PREVIOUS":{"nodeId":"e5fb3ac8-42f1-4f42-a44e-e971bb964a76","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"tMdcTal8Wo9HQimeGzGrhoIp3Zp9DyNWWf6t3Fcw+/c="},"NEXT":{"nodeId":"b34a9e00-061b-4662-83dd-22c86b218d2d","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"kcWKxsJxeCHaLjAWFgNxZ49/hdTl5Pu5zyHcdwnE1VQ="}},"hash":"zjGjN57IYt9Ofo+ryCEhLjE5JT91yYYqrPJD8jIHRIY=","text":"e. Uniformly thick (see 2.4). f. Unwrapped, sleeved, wrapped, or enveloped. # Length and Height of Flats\n\nThe length of a flat-size mailpiece is the longest dimension. The height is the dimension perpendicular to the length. # Minimum Flexibility Criteria for Flat-Size Pieces\n\nFlat-size pieces must be flexible. Boxes—with or without hinges, gaps, or breaks that allow the piece to bend—are not flats. Tight envelopes or wrappers that are filled with one or more boxes are not flats. At the customer’s option, a customer may perform the following test on his or her mailpieces. When a postal employee observes a customer demonstrating that a flat-size piece is flexible according to these standards, the employee does not need to perform the test. Test flats as defined in 201.4.3. Domestic Mail Manual • Updated 7-9-23\n---\n# Retail Mail: Physical Standards for Letters, Cards, Flats, and Parcels\n\n101 101.3.3\n\n|2.4|Uniform Thickness|\n|---|---|\n|Flat-size mailpieces must be uniformly thick so that any bumps, protrusions, or other irregularities do not cause more than 1/4-inch variance in thickness. When determining variance in thickness, exclude the outside edges of a mailpiece (1 inch from each edge) when the contents do not extend into those edges. Also, exclude the selvage of any polywrap covering (see 201.5.3) from this determination. Mailers must secure nonpaper contents to prevent shifting of more than 2 inches within the mailpiece if shifting would cause the piece to be nonuniform in thickness or would result in the contents bursting out of the mailpiece (see 601.3.3).|Flat-size mailpieces must be uniformly thick so that any bumps, protrusions, or other irregularities do not cause more than 1/4-inch variance in thickness. When determining variance in thickness, exclude the outside edges of a mailpiece (1 inch from each edge) when the contents do not extend into those edges. Also, exclude the selvage of any polywrap covering (see 201.5.3) from this determination.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"b34a9e00-061b-4662-83dd-22c86b218d2d":{"id_":"b34a9e00-061b-4662-83dd-22c86b218d2d","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"PREVIOUS":{"nodeId":"f4ce8987-74c6-411d-affc-04f9fd763ce6","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"zjGjN57IYt9Ofo+ryCEhLjE5JT91yYYqrPJD8jIHRIY="},"NEXT":{"nodeId":"06fa0ac2-e6ed-4f05-86d0-d255554bce6e","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"A2UXLnHXyq89Bw/jKaDyBzymx7urTExUUZPirFebAr0="}},"hash":"kcWKxsJxeCHaLjAWFgNxZ49/hdTl5Pu5zyHcdwnE1VQ=","text":"Mailers must secure nonpaper contents to prevent shifting of more than 2 inches within the mailpiece if shifting would cause the piece to be nonuniform in thickness or would result in the contents bursting out of the mailpiece (see 601.3.3).|\n\n|2.5|Ineligible Flat-Size Pieces|\n|---|---|\n|Flat-size mailpieces that do not meet the eligibility standards in 2.3 and 2.4 are considered parcels, and customers mailing these pieces must pay the applicable parcel prices.|Flat-size mailpieces that do not meet the eligibility standards in 2.3 and 2.4 are considered parcels, and customers mailing these pieces must pay the applicable parcel prices.|\n\n# Physical Standards for Parcels\n\n|3.1|Processing Categories|\n|---|---|\n|USPS categorizes parcels into one of three mail processing categories: machinable, irregular, or nonmachinable parcel. These categories are based on the physical dimensions of the piece, regardless of the placement (orientation) of the delivery address on the piece. For additional information on machinable, irregular, and nonmachinable processing categories, see 201.7.0.|USPS categorizes parcels into one of three mail processing categories: machinable, irregular, or nonmachinable parcel. These categories are based on the physical dimensions of the piece, regardless of the placement (orientation) of the delivery address on the piece. For additional information on machinable, irregular, and nonmachinable processing categories, see 201.7.0.|\n\n|3.2|Maximum Weight and Size|\n|---|---|\n|All parcels must be large enough to hold the required delivery address, return address, mailing labels, postage, barcode, endorsements, and other mail markings on the address side of the parcel. For mailability, all pieces 1/4 inch thick or less must be a minimum of 5 inches in length, 3-1/2 inches in height, and 0.007 inch in thickness. No mailpiece may weigh more than 70 pounds. Except for USPS Ground Advantage – Retail, which may not measure more than 130 inches in length and girth combined, no mailpiece may measure more than 108 inches in length and girth combined. For parcels, length is the distance of the longest dimension and girth is the distance around the thickest part.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"06fa0ac2-e6ed-4f05-86d0-d255554bce6e":{"id_":"06fa0ac2-e6ed-4f05-86d0-d255554bce6e","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"PREVIOUS":{"nodeId":"b34a9e00-061b-4662-83dd-22c86b218d2d","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"kcWKxsJxeCHaLjAWFgNxZ49/hdTl5Pu5zyHcdwnE1VQ="},"NEXT":{"nodeId":"0a6dc1cc-e4bb-4c3f-9d00-6478d5d76d18","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"VTDqqPBkOXBee0auCunLP/KbWEiJeDiNdPbUBHqEm98="}},"hash":"A2UXLnHXyq89Bw/jKaDyBzymx7urTExUUZPirFebAr0=","text":"Lower size or weight standards apply to mail addressed to some APOs and FPOs subject to 703.2.0 and 703.4.0 and for Department of State mail, subject to 703.3.0.|All parcels must be large enough to hold the required delivery address, return address, mailing labels, postage, barcode, endorsements, and other mail markings on the address side of the parcel. For mailability, all pieces 1/4 inch thick or less must be a minimum of 5 inches in length, 3-1/2 inches in height, and 0.007 inch in thickness. No mailpiece may weigh more than 70 pounds. Except for USPS Ground Advantage – Retail, which may not measure more than 130 inches in length and girth combined, no mailpiece may measure more than 108 inches in length and girth combined. For parcels, length is the distance of the longest dimension and girth is the distance around the thickest part. Lower size or weight standards apply to mail addressed to some APOs and FPOs subject to 703.2.0 and 703.4.0 and for Department of State mail, subject to 703.3.0.|\n\n|3.3|Two or More Packages|\n|---|---|\n|With the exception of USPS-produced Flat Rate Envelopes and Boxes, two or more packages may be mailed as a single parcel, if they are about the same size or shape, if they are securely wrapped or fastened together, and if they do not together exceed the weight or size limits.|With the exception of USPS-produced Flat Rate Envelopes and Boxes, two or more packages may be mailed as a single parcel, if they are about the same size or shape, if they are securely wrapped or fastened together, and if they do not together exceed the weight or size limits.|\n\nDomestic Mail Manual • Updated 7-9-23\n---\n# Retail Mail: Physical Standards for Letters, Cards, Flats, and Parcels\n\n|4.0|Additional Physical Standards for Priority Mail Express|\n|---|---|\n| |Each piece of Priority Mail Express may not weigh more than 70 pounds. The combined length and girth of a piece (the length of its longest side plus the distance around its thickest part) may not exceed 108 inches.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"0a6dc1cc-e4bb-4c3f-9d00-6478d5d76d18":{"id_":"0a6dc1cc-e4bb-4c3f-9d00-6478d5d76d18","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"PREVIOUS":{"nodeId":"06fa0ac2-e6ed-4f05-86d0-d255554bce6e","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"A2UXLnHXyq89Bw/jKaDyBzymx7urTExUUZPirFebAr0="},"NEXT":{"nodeId":"896d0cbf-2bd8-47b4-88dc-08e915f8601a","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"uhzxw8JWhOAuRn+Z33qhlYS/KfQIaCEQhOthjAhT2OU="}},"hash":"VTDqqPBkOXBee0auCunLP/KbWEiJeDiNdPbUBHqEm98=","text":"Lower size or weight standards apply to Priority Mail Express addressed to certain APO/FPO and DPOs. Priority Mail Express items must be large enough to hold the required mailing labels and indicia on a single optical plane without bending or folding.|\n\n|5.0|Additional Physical Standards for Priority Mail|\n|---|---|\n| |The maximum weight is 70 pounds. The combined length and girth of a piece (the length of its longest side plus the distance around its thickest part) may not exceed 108 inches. Lower size and weight standards apply for some APO/FPO and DPO mail subject to 703.2.0, and 703.4.0, and for Department of State mail subject to 703.3.0.|\n\n6.0\nAdditional Physical Standards for First-Class Mail and USPS Ground Advantage — Retail\n\n|6.1|Maximum Weight|\n|---|---|\n|6.1.1|First-Class Mail|\n| |First-Class Mail (letters and flats) must not exceed 13 ounces.|\n|6.1.2|USPS Ground Advantage — Retail|\n| |USPS Ground Advantage — Retail mail must not exceed 70 pounds.|\n\n|6.2|Cards Claimed at Card Prices|\n|---|---|\n|6.2.1|Card Price|\n| |A card may be a single or double (reply) stamped card or a single or double postcard. Stamped cards are available from USPS with postage imprinted on them. Postcards are commercially available or privately printed mailing cards. To be eligible for card pricing, a card and each half of a double card must meet the physical standards in 6.2 and the applicable eligibility for the price claimed. Ineligible cards are subject to letter-size pricing.|\n|6.2.2|Postcard Dimensions|\n| |Each card and part of a double card claimed at card pricing must be the following: a. Rectangular. b. Not less than 3-1/2 inches high, 5 inches long, and 0.007 inch thick. c. Not more than 4-1/4 inches high, or more than 6 inches long, or greater than 0.016 inch thick. d.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"896d0cbf-2bd8-47b4-88dc-08e915f8601a":{"id_":"896d0cbf-2bd8-47b4-88dc-08e915f8601a","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"PREVIOUS":{"nodeId":"0a6dc1cc-e4bb-4c3f-9d00-6478d5d76d18","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"VTDqqPBkOXBee0auCunLP/KbWEiJeDiNdPbUBHqEm98="},"NEXT":{"nodeId":"6e32fd1e-a32e-4886-a33d-e30ad0ea8bc9","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"+cy2c6zNC9XzXKqL7Ek0JYdbu9iCOd0cIJ+Rp5TnTxE="}},"hash":"uhzxw8JWhOAuRn+Z33qhlYS/KfQIaCEQhOthjAhT2OU=","text":"d. Not more than 3.5 ounces (Charge flat-size prices for First-Class Mail card-type pieces over 3.5 ounces.)|\n\nDomestic Mail Manual • Updated 7-9-23\n---\n# Retail Mail: Physical Standards for Letters, Cards, Flats, and Parcels\n\n|6.2.3|Other Cards|\n|---|---|\n| |A card that does not meet the applicable standards in 6.2 must not bear the words “Postcard” or “Double Postcard.”|\n|6.2.4|Paper or Card Stock|\n| |A card must be of uniform thickness and made of unfolded and uncreased paper or cardstock of approximately the quality and weight of a stamped card (i.e., a card available from USPS). A card must be formed either of one piece of paper or cardstock or of two pieces of paper permanently and uniformly bonded together. The stock used for a card may be of any color or surface that permits the legible printing of the address, postmark, and any required markings.|\n|6.2.5|Acceptable Attachments|\n| |a. A paper label, such as a wafer seal or decal affixed with permanent adhesive to the back side of the card, or within the message area on the address side, or to the left of the address block.|\n| |b. A label affixed with permanent adhesive for showing the delivery or return address.|\n| |c. A small reusable seal or decal prepared with pressure-sensitive and nonremovable adhesive that is intended to be removed from the first half of a double card and applied to the reply half.|\n|6.2.6|Unacceptable Attachment|\n| |a. Other than paper.|\n| |b. Not totally adhered to the card surface.|\n| |c. An encumbrance to postal processing.|\n|6.2.7|Tearing Guides|\n| |A card may have perforations or tearing guides if they do not eliminate or interfere with any address element, postage, marking, or endorsement and do not impair the physical integrity of the card.|\n|6.2.8|Address Side of Cards|\n| |The address side of a card is the side bearing the delivery address and postage. The address side may be formatted to contain a message area.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"6e32fd1e-a32e-4886-a33d-e30ad0ea8bc9":{"id_":"6e32fd1e-a32e-4886-a33d-e30ad0ea8bc9","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"PREVIOUS":{"nodeId":"896d0cbf-2bd8-47b4-88dc-08e915f8601a","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"uhzxw8JWhOAuRn+Z33qhlYS/KfQIaCEQhOthjAhT2OU="},"NEXT":{"nodeId":"dfe4c2c2-1cc7-4b04-8a15-88c781c14407","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"TZ2fyHYgXl1g3XcKsoFP8l99NyMgbQQxn+OmMwV16M8="}},"hash":"+cy2c6zNC9XzXKqL7Ek0JYdbu9iCOd0cIJ+Rp5TnTxE=","text":"The address side may be formatted to contain a message area. Cards that do not contain a message area on the address side are subject to the applicable standards for the price claimed. For the purposes of 6.2, miscellaneous graphics or printing, such as symbols, logos, or characters, that appear on the address side of cards not containing a message area are generally acceptable provided the items are not intended to convey a message.|\n|6.2.9|Double Cards|\n| |A double card (a double stamped card or double postcard) consists of two attached cards, one of which is designed to be detached by the recipient and returned by mail as a single card. Double cards are subject to these standards:|\n\nDomestic Mail Manual • Updated 7-9-23\n---\n# Retail Mail: Physical Standards for Letters, Cards, Flats, and Parcels\n\n101\n\n101.6.2.10\n\n|a.|The reply half of a double card must be used for reply only and may not be used to convey a message to the original addressee or to send statements of account. The reply half may be formatted for response purposes (e.g., contain blocks for completion by the addressee).|\n|---|---|\n|b.|A double card must be folded before mailing and prepared so that the address on the reply half is on the inside when the double card is originally mailed. The address side of the reply half may be prepared as Business Reply Mail, Courtesy Reply Mail, meter reply mail, or as a USPS Returns service label.|\n|c.|Plain stickers, seals, or a single wire stitch (staple) may be used to fasten the open edge at the top or bottom once the card is folded if affixed so that the inner surfaces of the cards can be readily examined. Fasteners must be affixed according to the applicable preparation requirements for the price claimed. Any sealing on the left and right sides of the cards, no matter the sealing process used, is not permitted.|\n|d.|The first half of a double card must be detached when the reply half is mailed for return.|\n\n6.2.10 Enclosures\n\nEnclosures in double postcards are prohibited at card prices.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"dfe4c2c2-1cc7-4b04-8a15-88c781c14407":{"id_":"dfe4c2c2-1cc7-4b04-8a15-88c781c14407","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"f38509cb-c288-4b17-8e3f-a62ec8289c59","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"wdJmeGpDoiNUY9U34nB7BC4oo3z2+xNe+yi/CBvX+Ig="},"PREVIOUS":{"nodeId":"6e32fd1e-a32e-4886-a33d-e30ad0ea8bc9","metadata":{"file_path":"/workspaces/ai_journey/my-create-llama-app/data/101.pdf","file_name":"101.pdf"},"hash":"+cy2c6zNC9XzXKqL7Ek0JYdbu9iCOd0cIJ+Rp5TnTxE="}},"hash":"TZ2fyHYgXl1g3XcKsoFP8l99NyMgbQQxn+OmMwV16M8=","text":"6.3 Nonmachinable Pieces\n\n6.3.1 Nonmachinable Letters\n\nLetter-size pieces (except card-size pieces) that meet one or more of the nonmachinable characteristics in 1.2 are subject to the nonmachinable surcharge (see 133.1.7). 6.3.2 Nonmachinable Flats\n\nFlat-size pieces that do not meet the standards in 2.0 are considered parcels, and the mailer must pay the applicable parcel price. 6.4 Parcels\n\n[7-9-23] USPS Ground Advantage — Retail parcels are eligible for USPS Tracking and Signature Confirmation service. A USPS Ground Advantage — Retail parcel is the following:\n\n- a. A mailpiece that exceeds any one of the maximum dimensions for a flat (large envelope). See 2.1. - b. A flat-size mailpiece, regardless of thickness, that is rigid or nonrectangular. - c. A flat-size mailpiece that is not uniformly thick under 2.4. - d. [7-9-23] A mailpiece that does not exceed 130 inches in combined length and girth. 7.0 Additional Physical Standards for Media Mail and Library Mail\n\nThese standards apply to Media Mail and Library Mail:\n\nDomestic Mail Manual • Updated 7-9-23\n---\n# Retail Mail: Physical Standards for Letters, Cards, Flats, and Parcels\n\n|101|101.6.4|\n|---|---|\n|a. No piece may weigh more than 70 pounds.| |\n|b. The combined length and girth of a piece (the length of its longest side plus the distance around its thickest part) may not exceed 108 inches.| |\n|c. Lower size or weight standards apply to mail addressed to certain APOs and FPOs, subject to 703.2.0 and 703.4.0 and for Department of State mail, subject to 703.3.0.| |\n\nDomestic Mail Manual • Updated 7-9-23\n---\nDomestic Mail Manual • Updated 7-9-23","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"a429e52d-e2fa-4d44-9ac2-bc2a8f3cd1b5":{"id_":"a429e52d-e2fa-4d44-9ac2-bc2a8f3cd1b5","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"NEXT":{"nodeId":"471ac574-b2f9-4831-893e-9261ea97782e","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"imt/tpiCQ9pQXqFg52KciRgBtB2cKt9sU6C9x3LId7A="}},"hash":"lQFD65AoOON3ZMwPkKK6wWnHsN0xFJmLFsGn0Vaxjjw=","text":"# GPT4All: An Ecosystem of Open Source Compressed Language Models\n\n|Yuvanesh Anand|Zach Nussbaum|Adam Treat|Aaron Miller|\n|---|---|---|---|\n|Nomic AI|Nomic AI|Nomic AI|Nomic AI|\n|yuvanesh@nomic.ai|zach@nomic.ai|adam@nomic.ai|aaron@nomic.ai|\n\n|Richard Guo|Ben Schmidt|GPT4All Community|\n|---|---|---|\n|Nomic AI|Nomic AI|Planet Earth|\n|richard@nomic.ai|ben@nomic.ai| |\n\n|Brandon Duderstadt|Andriy Mulyar|\n|---|---|\n|Nomic AI|Nomic AI|\n|brandon@nomic.ai|andriy@nomic.ai|\n\nAbstract\n\nLarge language models (LLMs) have recently achieved human-level performance on a range of professional and academic benchmarks. The accessibility of these models has lagged behind their performance. State-of-the-art LLMs require costly infrastructure; are only accessible via rate-limited, geo-locked, and censored web interfaces; and lack publicly available code and technical reports. In this paper, we tell the story of GPT4All, a popular open source repository that aims to democratize access to LLMs. We outline the technical details of the original GPT4All model family, as well as the evolution of the GPT4All project from a single model into a fully fledged open source ecosystem. It is our hope that this paper acts as both a technical overview of the original GPT4All models as well as a case study on the subsequent growth of the GPT4All open source ecosystem. # The Original GPT4All Model\n\n# Data Collection and Curation\n\nTo train the original GPT4All model, we collected roughly one million prompt-response pairs using the GPT-3.5-Turbo OpenAI API between March 20, 2023 and March 26th, 2023. In particular, we gathered GPT-3.5-Turbo responses to prompts of three publicly available datasets: the unified chip2 subset of LAION OIG, a random sub-sample of Stackoverflow Questions, and a sub-sample of Bigscience/P3.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"471ac574-b2f9-4831-893e-9261ea97782e":{"id_":"471ac574-b2f9-4831-893e-9261ea97782e","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"PREVIOUS":{"nodeId":"a429e52d-e2fa-4d44-9ac2-bc2a8f3cd1b5","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"lQFD65AoOON3ZMwPkKK6wWnHsN0xFJmLFsGn0Vaxjjw="},"NEXT":{"nodeId":"738793d8-58d1-4f9e-bffd-6f71ccf6db21","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"4uas+LiWQW6qv95wQ+rqprRYWnuVkn1tAdMeOBhVpeM="}},"hash":"imt/tpiCQ9pQXqFg52KciRgBtB2cKt9sU6C9x3LId7A=","text":"Following the approach in Stanford Alpaca, an open source LLaMA variant that came just before GPT4All, we focused substantial effort on dataset curation. The collected dataset was loaded into Atlas—a visual interface for exploring and tagging massive unstructured datasets—for data curation. Using Atlas, we were able to... ---\nlas, we identified and removed subsets of the data where The LLaMA model that GPT4All was based on was GPT-3.5-Turbo refused to respond, had malformed output, or produced a very short response. This resulted in the removal of the entire Bigscience/P3 subset of our data, as many P3 prompts induced responses that were simply one word. After curation, we were left with a set of 437,605 prompt-response pairs, which we visualize in Figure 1a. 2.2 Model Training\n\nThe original GPT4All model was a fine-tuned variant of LLaMA 7B. In order to train it more efficiently, we froze the base weights of LLaMA, and only trained a small set of LoRA (Hu et al., 2021) weights during the fine-tuning process. Detailed model hyper-parameters and training code can be found in our associated code repository 1. 2.3 Model Access\n\nWe publicly released all data, training code, and model weights for the community to build upon. Further, we provided a 4-bit quantized version of the model, which enabled users to run it on their own commodity hardware without transferring data to a 3rd party service. Our research and development costs were dominated by ∼$800 in GPU spend (rented from Lambda Labs and Paperspace) and ∼$500 in OpenAI API spend. Our final GPT4All model could be trained in about eight hours on a Lambda Labs DGX A100 8x 80GB for a total cost of ∼$100. 2.4 Model Evaluation\n\nWe performed a preliminary evaluation of our model using the human evaluation data from the Self Instruct paper (Wang et al., 2023). We reported the ground truth perplexity of our model against what was, to our knowledge, the best openly available alpaca-lora model at the time, provided by user chainyo on HuggingFace.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"738793d8-58d1-4f9e-bffd-6f71ccf6db21":{"id_":"738793d8-58d1-4f9e-bffd-6f71ccf6db21","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"PREVIOUS":{"nodeId":"471ac574-b2f9-4831-893e-9261ea97782e","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"imt/tpiCQ9pQXqFg52KciRgBtB2cKt9sU6C9x3LId7A="},"NEXT":{"nodeId":"5dcbee3d-9b6f-4f67-94a9-f1d9143c260d","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"d3sqZCCayxNtPmYGaE+cEX6KzgxFx+4rePD0Ybh1kuE="}},"hash":"4uas+LiWQW6qv95wQ+rqprRYWnuVkn1tAdMeOBhVpeM=","text":"Both models had very large perplexities on a small number of tasks, so we reported perplexities clipped to a maximum of 100. We found that GPT4All produces stochastically lower ground truth perplexities than alpaca-lora (Anand et al., 2023). 3 From a Model to an Ecosystem\n\n3.1 GPT4All-J: Repository Growth and the implications of the LLaMA License\n\nThe GPT4All repository grew rapidly after its release, gaining over 20000 GitHub stars in just one week, as shown in Figure 2. This growth was supported by an in-person hackathon hosted in New York City three days after the model release, which attracted several hundred participants. As the Nomic discord, the home of online discussion about GPT4All, ballooned to over 10000 people, one thing became very clear - there was massive demand for a model that could be used commercially. 3.2 GPT4All-Snoozy: the Emergence of the GPT4All Ecosystem\n\nGPT4All-Snoozy was developed using roughly the same procedure as the previous GPT4All models, but with a few key modifications. First, GPT4All-Snoozy used the LLaMA-13B base model due to its superior base metrics when compared to GPT-J. Next, GPT4All-Snoozy incorporated the Dolly’s training data into its train mix. After data curation and deduplication with Atlas, this yielded a training set of 739,259 total prompt-response pairs. We dubbed the model that resulted from training on this improved dataset GPT4All-Snoozy. As shown in Figure 1, GPT4All-Snoozy had the best average score on our evaluation benchmark of any model in the ecosystem at the time of its release. Concurrently with the development of GPT4All, several organizations such as LMSys, Stability AI, BAIR, and Databricks built and deployed open source language models. We heard increasingly from the community that they wanted quantized versions of these models for local use. As we realized that organizations with ever more resources were developing source language models, we decided to pivot our effort away from training increasingly capable models and towards providing easy access to the plethora of models being produced by the open source community.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"5dcbee3d-9b6f-4f67-94a9-f1d9143c260d":{"id_":"5dcbee3d-9b6f-4f67-94a9-f1d9143c260d","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"PREVIOUS":{"nodeId":"738793d8-58d1-4f9e-bffd-6f71ccf6db21","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"4uas+LiWQW6qv95wQ+rqprRYWnuVkn1tAdMeOBhVpeM="},"NEXT":{"nodeId":"91ca27b1-906b-4f81-a22d-6f7f38dad6c2","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"XgUFWRN1IQfJdsq4uXZ0Z5NKQSjsl2wfNbzt2cP5Kto="}},"hash":"d3sqZCCayxNtPmYGaE+cEX6KzgxFx+4rePD0Ybh1kuE=","text":"Practically, this meant spending our time compressing open source models for use on commodity hardware, providing stable and simple high-level model APIs, and supporting a GUI for no code model experimentation. 3.3 The Current State of GPT4All\n\nToday, GPT4All is focused on improving the accessibility of open source language models. The repository\n---\n# Figure 1: TSNE visualizations\n\nShowing the progression of the GPT4All train set. Panel (a) shows the original uncurated data. The red arrow denotes a region of highly homogeneous prompt-response pairs. The coloring denotes which open dataset contributed the prompt. Panel (b) shows the original GPT4All data after curation. This panel, as well as panels (c) and (d) are colored by topic, which Atlas automatically extracts. Notice that the large homogeneous prompt-response blobs no longer appear. Panel (c) shows the GPT4All-J dataset. The \"starburst\" clusters introduced on the right side of the panel correspond to the newly added creative data. Panel (d) shows the final GPT4All-snoozy dataset. All datasets have been released to the public, and can be interactively explored online. In the web version of this article, you can click on a panel to be taken to its interactive visualization.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"91ca27b1-906b-4f81-a22d-6f7f38dad6c2":{"id_":"91ca27b1-906b-4f81-a22d-6f7f38dad6c2","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"PREVIOUS":{"nodeId":"5dcbee3d-9b6f-4f67-94a9-f1d9143c260d","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"d3sqZCCayxNtPmYGaE+cEX6KzgxFx+4rePD0Ybh1kuE="},"NEXT":{"nodeId":"9ea3c559-edbb-4c2d-a51c-73672d84dd55","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"qdDh1ADBWq4f3SdbGVIFomBquVGyhfuqUap0oCh7VWk="}},"hash":"XgUFWRN1IQfJdsq4uXZ0Z5NKQSjsl2wfNbzt2cP5Kto=","text":"# Table 1: Evaluations of all language models in the GPT4All ecosystem as of August 1, 2023\n\n|Model|BoolQ|PIQA|HellaSwag|WinoG.|ARC-e|ARC-c|OBQA|Avg.|\n|---|---|---|---|---|---|---|---|---|\n|GPT4All-J 6B v1.0*|73.4|74.8|63.4|64.7|54.9|36|40.2|58.2|\n|GPT4All-J v1.1-breezy*|74|75.1|63.2|63.6|55.4|34.9|38.4|57.8|\n|GPT4All-J v1.2-jazzy*|74.8|74.9|63.6|63.8|56.6|35.3|41|58.6|\n|GPT4All-J v1.3-groovy*|73.6|74.3|63.8|63.5|57.7|35|38.8|58.1|\n|GPT4All-J Lora 6B*|68.6|75.8|66.2|63.5|56.4|35.7|40.2|58.1|\n|GPT4All LLaMa Lora 7B*|73.1|77.6|72.1|67.8|51.1|40.4|40.2|60.3|\n|GPT4All 13B snoozy*|83.3|79.2|75|71.3|60.9|44.2|43.4|65.3|\n|GPT4All Falcon|77.6|79.8|74.9|70.1|67.9|43.4|42.6|65.2|\n|Nous-Hermes (Nous-Research, 2023b)|79.5|78.9|80|71.9|74.2|50.9|46.4|68.8|\n|Nous-Hermes2 (Nous-Research, 2023c)|83.9|80.7|80.1|71.3|75.7|52.1|46.2|70|\n|Nous-Puffin (Nous-Research, 2023d)|81.5|80.7|80.4|72.5|77.6|50.7|45.6|69.9|\n|Dolly 6B* (Conover et al., 2023a)|68.8|77.3|67.6|63.9|62.9|38.7|41.2|60.1|\n|Dolly 12B* (Conover et al., 2023b)|56.7|75.4|71|62.2|64.6|38.5|40.4|58.4|\n|Alpaca 7B* (Taori et al., 2023)|73.9|77.2|73.9|66.1|59.8|43.3|43.4|62.5|\n|Alpaca Lora 7B* (Wang, 2023)|74.3|79.3|74|68.8|56.6|43.9|42.6|62.8|\n|GPT-J* 6.7B (Wang and Komatsuzaki, 2021)|65.4|76.2|66.2|64.1|62.2|36.6|38.2|58.4|\n|LLama 7B* (Touvron et al., 2023)|73.1|77.4|73|66.9|52.5|41.4|42.4|61|\n|LLama 13B* (Touvron et al., 2023)|68.5|79.1|76.2|70.1|60|44.6|42.2|63|\n|Pythia 6.7B* (Biderman et al., 2023)|63.5|76.3|64|61.1|61.3|35.2|37.2|56.9|\n|Pythia 12B* (Biderman et al., 2023)|67.7|76.6|67.3|63.8|63.9|34.8|38|58.9|\n|Fastchat T5* (Zheng et al., 2023)|81.5|64.6|46.3|61.8|49.3|33.3|39.4|53.7|\n|Fastchat Vicuña* 7B (Zheng et al., 2023)|76.6|77.2|70.7|67.3|53.5|41.2|40.8|61|\n|Fastchat Vicuña 13B* (Zheng et al., 2023)|81.5|76.8|73.3|66.7|57.4|42.7|43.6|63.1|\n|StableVicuña RLHF* (Stability-AI, 2023)|82.3|78.6|74.1|70.9|61|43.5|44.4|65|\n|StableLM Tuned* (Stability-AI, 2023)|62.5|71.2|53.6|54.8|52.4|31.1|33.4|51.3|\n|StableLM Base* (Stability-AI, 2023)|60.1|67.4|41.2|50.1|44.9|27|32|46.1|\n|Koala 13B* (Geng et al., 2023)|76.5|77.9|72.6|68.8|54.3|41|42.8|62|\n|Open Assistant Pythia 12B*|67.9|78|68.1|65|64.2|40.4|43.2|61|\n|Mosaic MPT7B (MosaicML-Team, 2023)|74.8|79.3|76.3|68.6|70|42.2|42.6|64.8|\n|Mosaic mpt-instruct (MosaicML-Team, 2023)|74.3|80.4|77.2|67.8|72.2|44.6|43|65.6|\n|Mosaic mpt-chat (MosaicML-Team, 2023)|77.1|78.2|74.5|67.5|69.4|43.3|44.2|64.9|\n|Wizard 7B (Xu et al., 2023)|78.4|77.2|69.9|66.5|56.8|40.5|42.6|61.7|\n|Wizard 7B Uncensored (Xu et al., 2023)|77.7|74.2|68|65.2|53.5|38.7|41.6|59.8|\n|Wizard 13B Uncensored (Xu et al., 2023)|78.4|75.5|72.1|69.5|57.5|40.4|44|62.5|\n|GPT4-x-Vicuna-13b (Nous-Research, 2023a)|81.3|75|75.2|65|58.7|43.9|43.6|63.2|\n|Falcon 7b (Almazrouei et al., 2023)|73.6|80.7|76.3|67.3|71|43.3|44.4|65.2|\n|Falcon 7b instruct (Almazrouei et al., 2023)|70.9|78.6|69.8|66.7|67.9|42.7|41.2|62.5|\n|text-davinci-003|88.1|83.8|83.4|75.8|83.9|63.9|51|75.7|\n---\n# Figure 2: Comparison of the github start growth of GPT4All, Meta’s LLaMA, and Stanford’s Alpaca.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"9ea3c559-edbb-4c2d-a51c-73672d84dd55":{"id_":"9ea3c559-edbb-4c2d-a51c-73672d84dd55","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"PREVIOUS":{"nodeId":"91ca27b1-906b-4f81-a22d-6f7f38dad6c2","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"XgUFWRN1IQfJdsq4uXZ0Z5NKQSjsl2wfNbzt2cP5Kto="},"NEXT":{"nodeId":"e1125a12-3a4c-419f-8cc2-90532edf42eb","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"+T8LNQXRIUTx1WRuCwn7wGwQ53hUKwKVfzrjyZmR7Z0="}},"hash":"qdDh1ADBWq4f3SdbGVIFomBquVGyhfuqUap0oCh7VWk=","text":"We conjecture that GPT4All achieved and maintains faster ecosystem growth due to the focus on access, which allows more users to meaningfully participate. Provides compressed versions of open source models \"just work\" on any machine, whether it comes equipped for use on commodity hardware, stable and simple high-level model APIs, and a GUI for no code model experimentation. The project continues to increase in popularity, and as of August 1 2023, has garnered over 50000 GitHub stars and over 5000 forks. GPT4All currently provides native support and benchmark data for over 35 models, and includes several models co-developed with industry partners such as Replit and Hugging Face. GPT4All also provides high level model APIs in languages including Python, Typescript, Go, C#, and Java, among others. Furthermore, the GPT4All no code GUI currently supports the workflows of over 50000 monthly active users, with over 25% of users coming back to the tool every day of the week. (Note that all GPT4All user data is collected on an opt-in basis. ) GPT4All has become the top language model integration in the popular open source AI orchestration library LangChain (Chase, 2022), and powers many popular open source projects such as PrivateGPT (imartinez, 2023), Quiver (StanGi- rard, 2023), and MindsDB (MindsDB, 2023), among others. GPT4All is the 3rd fastest growing GitHub repository of all time (Leo, 2023), and is the 185th most popular repository on the platform, by star count. # The Future of GPT4All\n\nIn the future, we will continue to grow GPT4All, supporting it as the de facto solution for LLM accessibility. Concretely, this means continuing to compress and distribute important open-source language models developed by the community, as well as compressing and distributing increasingly multimodal AI models. Furthermore, we will expand the set of hardware devices that GPT4All models run on, so that GPT4All models\n\n# Limitations\n\nBy enabling access to large language models, the GPT4All project also inherits many of the ethical concerns associated with generative models.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"e1125a12-3a4c-419f-8cc2-90532edf42eb":{"id_":"e1125a12-3a4c-419f-8cc2-90532edf42eb","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"PREVIOUS":{"nodeId":"9ea3c559-edbb-4c2d-a51c-73672d84dd55","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"qdDh1ADBWq4f3SdbGVIFomBquVGyhfuqUap0oCh7VWk="},"NEXT":{"nodeId":"8a6787c5-02ed-4c62-9927-93854dedfab9","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"8bpZ7Bl5pBtcY3hGz8tp3LPb/ylxh6Sup3eSVlLqYUQ="}},"hash":"+T8LNQXRIUTx1WRuCwn7wGwQ53hUKwKVfzrjyZmR7Z0=","text":"Principal among these is the concern that unfiltered language models like GPT4All enable malicious users to generate content that could be harmful and dangerous (e.g., instructions on building bioweapons). While we recognize this risk, we also acknowledge the risk of concentrating this technology in the hands of a limited number of increasingly secretive research groups. We believe that the risk of focusing on the benefits of language model technology significantly outweighs the risk of misuse, and hence we prefer to make the technology as widely available as possible. Finally, we realize the challenge in assigning credit for large-scale open source initiatives. We make a first attempt at fair credit assignment by explicitly including the GPT4All open source developers as authors on this work, but recognize that this is insufficient fully characterize everyone involved in the GPT4All effort. Furthermore, we acknowledge the difficulty in citing open source works that do not necessarily have standardized citations, and do our best in this paper to provide URLs to projects whenever possible. We encourage further research in the area of open source credit assignment, and hope to be able to support some of this research ourselves in the future. ---\n# References\n\nMosaicML-Team. 2023. Introducing mpt-7b: A new standard for open-source, commercially usable llms. Nomic AI. 2023. Atlas. https://atlas.nomic.ai/. Accessed: 2023-08-07. Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al-shamsi, Alessandro Cappelli, Ruxandra Cojocaru, Merouane Debbah, Etienne Goffinet, Daniel Heslow, Julien Launay, Quentin Malartic, Badreddine Noune, Baptiste Pannier, and Guilherme Penedo. 2023. Falcon-40B: an open large language model wip state-of-pe-art performance. Yuvanesh Anand, Zach Nussbaum, Brandon Duderdstadt, Benjamin Schmidt, and Andriy Mulyar. 2023. Gpt4all: Training an assistant-style chatbot wip large scale data distillation from gpt-3.5-turbo. https://gipub.com/nomic-ai/gpt4all. BBC News. 2023. Chatgpt banned in Italy over privacy concerns.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"8a6787c5-02ed-4c62-9927-93854dedfab9":{"id_":"8a6787c5-02ed-4c62-9927-93854dedfab9","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"PREVIOUS":{"nodeId":"e1125a12-3a4c-419f-8cc2-90532edf42eb","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"+T8LNQXRIUTx1WRuCwn7wGwQ53hUKwKVfzrjyZmR7Z0="},"NEXT":{"nodeId":"4eeb77e2-3b13-4e67-896e-450b8cf1055c","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"g2+ZoDIDFSb4a/FtXoUmSb8awsJW2LxkK4cA4Gn9U40="}},"hash":"8bpZ7Bl5pBtcY3hGz8tp3LPb/ylxh6Sup3eSVlLqYUQ=","text":"BBC News. 2023. Chatgpt banned in Italy over privacy concerns. BBC News. Stella Biderman, Hailey Schoelkopf, Quentin Anpony, Herbie Bradley, Kyle O’Brien, Eric Hallahan, Mohammad Aflah Khan, Shivanshu Purohit, USVSN Sai Prashanp, Edward Raff, Aviya Skowron, Lintang Sutawika, and Oskar van der Wal. 2023. Pypia: A suite for analyzing large language models across training and scaling. Harrison Chase. 2022. langchain. https://gipub.com/langchain-ai/langchain. Mike Conover, Matt Hayes, Ankit Mapur, Xiangrui Meng, Jianwei Xie, Jun Wan, Ali Ghodsi, Patrick Wendell, and Matei Zaharia. 2023a. Hello dolly: Democratizing pe magic of chatgpt wip open models. Mike Conover, Matt Hayes, Ankit Mapur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023b. Free dolly: Introducing pe world’s first truly open instruction-tuned llm. Xinyang Geng, Arnav Gudibande, Hao Liu, Eric Wallace, Pieter Abbeel, Sergey Levine, and Dawn Song. 2023. Koala: A dialogue model for academic research. Blog post. Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of large language models. imartinez. 2023. privategpt. https://gipub.com/imartinez/privateGPT. Oscar Leo. 2023. GitHub: The Fastest Growing Repositories of All Time. Robert McMillan. 2023. A meta platforms leak put powerful ai in pe hands of everyone. The Wall Street Journal. MindsDB. 2023. Mindsdb. https://gipub.com/mindsdb/mindsdb. GitHub repository.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"},"4eeb77e2-3b13-4e67-896e-450b8cf1055c":{"id_":"4eeb77e2-3b13-4e67-896e-450b8cf1055c","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"excludedEmbedMetadataKeys":[],"excludedLlmMetadataKeys":[],"relationships":{"SOURCE":{"nodeId":"feb76c50-95c8-4b53-9cac-d964e2824900","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"GyU1htIRSsTMTeRyVbtYXSy6un/EUMN/nBrE37UqvqU="},"PREVIOUS":{"nodeId":"8a6787c5-02ed-4c62-9927-93854dedfab9","metadata":{"file_path":"/workspaces/ai_journey/create-llama-npx/my-create-llama-app/data/gpt4all-paper.pdf","file_name":"gpt4all-paper.pdf"},"hash":"8bpZ7Bl5pBtcY3hGz8tp3LPb/ylxh6Sup3eSVlLqYUQ="}},"hash":"g2+ZoDIDFSb4a/FtXoUmSb8awsJW2LxkK4cA4Gn9U40=","text":"https://gipub.com/mindsdb/mindsdb. GitHub repository. # The Verge\n\nMeta’s powerful ai language model has leaked online — what happens now? The Verge. James Vincent. 2023. As an ai generated language model: The phrase pat shows how ai is polluting pe web. The Verge. ---\nBen Wang and Aran Komatsuzaki. 2021. GPT-J-6B: A 6 Billion Parameter Autoregressive Language Model. https://github.com/kingoflolz/mesh-transformer-jax\n\nEric J. Wang. 2023. alpaca-lora. https://github.com/tloen/alpaca-lora GitHub repository. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2023. Self-instruct: Aligning language models with self-generated instructions. Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023. Wizardlm: Empowering large language models to follow complex instructions. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023. Judging llm-as-a-judge with mt-bench and chatbot arena.","textTemplate":"","metadataSeparator":"\n","type":"TEXT"}},"type":"simple_dict"}}}